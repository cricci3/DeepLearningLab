{"cells":[{"cell_type":"markdown","metadata":{},"source":["# CLAUDIO RICCI"]},{"cell_type":"markdown","metadata":{},"source":["## Packages"]},{"cell_type":"code","execution_count":1,"metadata":{"ExecuteTime":{"end_time":"2024-12-05T09:31:30.777483Z","start_time":"2024-12-05T09:31:30.704856Z"},"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-12-26T14:44:15.506881Z","iopub.status.busy":"2024-12-26T14:44:15.506547Z","iopub.status.idle":"2024-12-26T14:44:18.747540Z","shell.execute_reply":"2024-12-26T14:44:18.746622Z","shell.execute_reply.started":"2024-12-26T14:44:15.506841Z"},"trusted":true},"outputs":[],"source":["import networkx as nx # For graphs\n","import pickle # For data parsing\n","from networkx.algorithms.approximation import greedy_tsp # For approx TSP\n","import torch\n","import numpy as np\n","from torch.utils.data import DataLoader, random_split, Dataset\n","from torch.nn import Transformer"]},{"cell_type":"markdown","metadata":{},"source":["## Helper functions"]},{"cell_type":"code","execution_count":2,"metadata":{"ExecuteTime":{"end_time":"2024-12-05T09:31:30.806883Z","start_time":"2024-12-05T09:31:30.798896Z"},"execution":{"iopub.execute_input":"2024-12-26T14:44:18.750277Z","iopub.status.busy":"2024-12-26T14:44:18.749713Z","iopub.status.idle":"2024-12-26T14:44:18.763248Z","shell.execute_reply":"2024-12-26T14:44:18.762242Z","shell.execute_reply.started":"2024-12-26T14:44:18.750234Z"},"trusted":true},"outputs":[],"source":["\n","def tour_length(G, tour):\n","    \"\"\"\n","    Compute the length of a tour. A tour is a list having elments 0 and -1 equal\n","    \"\"\"\n","    assert tour[0] == tour[-1], \"Not valid tour\"\n","    estimated = 0\n","    for i in range(n):\n","        estimated += G[tour[i]][tour[i + 1]]['weight']\n","    return estimated\n","\n","def greedy_algorithm(G):\n","    \"\"\"\n","    Run the value of the greedy approximation algorithm on graph G\n","    \"\"\"\n","    return tour_length(G, greedy_tsp(G, weight='weight'))\n","\n","def random_tour(G, seed = 42):\n","    \"\"\"\n","    Return the value of a random tour\n","    \"\"\"\n","    np.random.seed(seed)\n","    n = G.number_of_nodes()\n","    tour = [0]\n","    for i in range(1, n):\n","        next_node = np.random.choice([j for j in range(n) if j not in tour])\n","        tour.append(next_node)\n","    tour.append(0)\n","\n","def transformer_tsp(G, model, DEVICE = 'cpu'):\n","    \"\"\"\n","    Evaluate your (trained) model on G\n","    \"\"\"\n","    # Set the model in evaluation mode\n","    model.eval()\n","\n","    # Note: number of edges is constant ed equal to n(n-1)/2\n","    n = G.number_of_nodes()\n","    \n","    # Get node coordinates\n","    attr = nx.get_node_attributes(G, 'pos')\n","    x = []\n","    for i in range(n):\n","        x.append(torch.tensor(attr[i], dtype=torch.float32))\n","\n","    # From list of tensors to tensor 2d\n","    x = torch.stack(x)    \n","\n","    tour = [0]\n","    y = torch.tensor(tour, dtype=torch.long)\n","    x = x.to(DEVICE).unsqueeze(0)\n","    y = y.to(DEVICE).unsqueeze(0)\n","    \n","    # Predict the next node\n","    out = transformer_model(x, y)\n","    \n","    # Loop until the tour is complete\n","    while len(tour) < n:\n","        _, idx = torch.topk(out, n, dim=2)\n","        for i in range(n):\n","            # Check if the node is already in the tour\n","            if idx[0, 0, i] not in tour:\n","                tour.append(idx[0, 0, i])\n","                break\n","        y = torch.tensor(tour)\n","        y = y.to(DEVICE).unsqueeze(0)\n","        out = transformer_model(x, y)\n","    \n","    tour = [int(i) for i in tour] + [0] # Append the starting node (that is hard-coded to 0)\n","    return tour_length(G, tour)\n","\n","\n","\n","def gap(G, model = None, model_GA = None, random_seed = 42, device = 'cpu'):\n","    \"\"\"\n","    Compute the gap between the optimal solution on graph G and all the analyzed methods\n","    \"\"\"\n","\n","        \n","    # Optimal value (hard-coded in the graph)\n","    TSP = sum([G[i][j]['weight']*G[i][j]['tour'] for (i, j) in G.edges()]) # Optimal\n","\n","    # Gaps dictionary\n","    gaps = {'greedy' : 0, 'random' : 0, 'transformer_tsp': 0, 'transformer_tsp_acc_grad': 0}\n","    gaps['greedy'] = 100* (greedy_algorithm(G) -  TSP) / TSP\n","    gaps['random'] = 100 * (random_tour(G, random_seed) - TSP) / TSP\n","    if model is not None:\n","        gaps['transformer_tsp'] = 100 * (transformer_tsp(G, model, DEVICE=device) - TSP) / TSP\n","    else:\n","        gaps['transformer_tsp'] = float('inf') # In case you just train with GA\n","        \n","    if model_GA is not None:\n","        gaps['transformer_tsp_acc_grad'] = 100 * (transformer_tsp(G, model_GA, DEVICE=device) - TSP) / TSP\n","    else:\n","        gaps['transformer_tsp_acc_grad'] = float('inf') # In case you just train without GA\n","    return gaps    \n","    "]},{"cell_type":"markdown","metadata":{},"source":["## Dataset & Dataloader"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-12-26T14:44:18.766998Z","iopub.status.busy":"2024-12-26T14:44:18.766731Z","iopub.status.idle":"2024-12-26T14:44:18.895625Z","shell.execute_reply":"2024-12-26T14:44:18.894704Z","shell.execute_reply.started":"2024-12-26T14:44:18.766972Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'list'>\n","<class 'tuple'>\n","<class 'networkx.classes.graph.Graph'>\n","<class 'list'>\n","(<networkx.classes.graph.Graph object at 0x7a0c486dfa30>, [0, 3, 14, 2, 9, 6, 19, 13, 12, 16, 7, 18, 8, 17, 5, 11, 10, 15, 1, 4, 0])\n"]}],"source":["# Load the dummy dataset, get a single data item and explain its Python type\n","with open('/kaggle/input/tspinstances/dummy_20_DLL_ass4.pkl', 'rb') as file:\n","    dummy = pickle.load(file)\n","\n","print(type(dummy)) # list\n","print(type(dummy[0]))  # The type of the first object -> tople\n","print(type(dummy[0][0]))  # The type of the first item of a tuple -> Graph\n","print(type(dummy[0][1]))  # The type of the first item of a tuple -> list\n","print(dummy[0])"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-12-26T14:44:18.898603Z","iopub.status.busy":"2024-12-26T14:44:18.898330Z","iopub.status.idle":"2024-12-26T14:44:18.905087Z","shell.execute_reply":"2024-12-26T14:44:18.904020Z","shell.execute_reply.started":"2024-12-26T14:44:18.898576Z"},"trusted":true},"outputs":[{"data":{"text/plain":["EdgeView([(0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (0, 8), (0, 9), (0, 10), (0, 11), (0, 12), (0, 13), (0, 14), (0, 15), (0, 16), (0, 17), (0, 18), (0, 19), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (1, 7), (1, 8), (1, 9), (1, 10), (1, 11), (1, 12), (1, 13), (1, 14), (1, 15), (1, 16), (1, 17), (1, 18), (1, 19), (2, 3), (2, 4), (2, 5), (2, 6), (2, 7), (2, 8), (2, 9), (2, 10), (2, 11), (2, 12), (2, 13), (2, 14), (2, 15), (2, 16), (2, 17), (2, 18), (2, 19), (3, 4), (3, 5), (3, 6), (3, 7), (3, 8), (3, 9), (3, 10), (3, 11), (3, 12), (3, 13), (3, 14), (3, 15), (3, 16), (3, 17), (3, 18), (3, 19), (4, 5), (4, 6), (4, 7), (4, 8), (4, 9), (4, 10), (4, 11), (4, 12), (4, 13), (4, 14), (4, 15), (4, 16), (4, 17), (4, 18), (4, 19), (5, 6), (5, 7), (5, 8), (5, 9), (5, 10), (5, 11), (5, 12), (5, 13), (5, 14), (5, 15), (5, 16), (5, 17), (5, 18), (5, 19), (6, 7), (6, 8), (6, 9), (6, 10), (6, 11), (6, 12), (6, 13), (6, 14), (6, 15), (6, 16), (6, 17), (6, 18), (6, 19), (7, 8), (7, 9), (7, 10), (7, 11), (7, 12), (7, 13), (7, 14), (7, 15), (7, 16), (7, 17), (7, 18), (7, 19), (8, 9), (8, 10), (8, 11), (8, 12), (8, 13), (8, 14), (8, 15), (8, 16), (8, 17), (8, 18), (8, 19), (9, 10), (9, 11), (9, 12), (9, 13), (9, 14), (9, 15), (9, 16), (9, 17), (9, 18), (9, 19), (10, 11), (10, 12), (10, 13), (10, 14), (10, 15), (10, 16), (10, 17), (10, 18), (10, 19), (11, 12), (11, 13), (11, 14), (11, 15), (11, 16), (11, 17), (11, 18), (11, 19), (12, 13), (12, 14), (12, 15), (12, 16), (12, 17), (12, 18), (12, 19), (13, 14), (13, 15), (13, 16), (13, 17), (13, 18), (13, 19), (14, 15), (14, 16), (14, 17), (14, 18), (14, 19), (15, 16), (15, 17), (15, 18), (15, 19), (16, 17), (16, 18), (16, 19), (17, 18), (17, 19), (18, 19)])"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["dummy[0][0].edges"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-12-26T14:44:18.906718Z","iopub.status.busy":"2024-12-26T14:44:18.906381Z","iopub.status.idle":"2024-12-26T14:44:18.919887Z","shell.execute_reply":"2024-12-26T14:44:18.919085Z","shell.execute_reply.started":"2024-12-26T14:44:18.906669Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Edges and attributes:\n","  Edge (0, 1):\n","     Weight: 0.4287846201876535\n","     Tour: 0\n","  Edge (0, 2):\n","     Weight: 0.20417626260418414\n","     Tour: 0\n","  Edge (0, 3):\n","     Weight: 0.08154537102129383\n","     Tour: 1\n","  Edge (0, 4):\n","     Weight: 0.08031174728403137\n","     Tour: 1\n","  Edge (0, 5):\n","     Weight: 0.5612080164024046\n","     Tour: 0\n","  Edge (0, 6):\n","     Weight: 0.2295012043541082\n","     Tour: 0\n","  Edge (0, 7):\n","     Weight: 0.514746498076055\n","     Tour: 0\n","  Edge (0, 8):\n","     Weight: 0.5266704818162102\n","     Tour: 0\n","  Edge (0, 9):\n","     Weight: 0.15283720045858457\n","     Tour: 0\n","  Edge (0, 10):\n","     Weight: 0.3556451198878696\n","     Tour: 0\n","  Edge (0, 11):\n","     Weight: 0.24046942531001395\n","     Tour: 0\n","  Edge (0, 12):\n","     Weight: 0.3189080728571583\n","     Tour: 0\n","  Edge (0, 13):\n","     Weight: 0.49621109228471955\n","     Tour: 0\n","  Edge (0, 14):\n","     Weight: 0.1765729477183786\n","     Tour: 0\n","  Edge (0, 15):\n","     Weight: 0.4701608359103749\n","     Tour: 0\n","  Edge (0, 16):\n","     Weight: 0.3309416339870591\n","     Tour: 0\n","  Edge (0, 17):\n","     Weight: 0.5383964713091507\n","     Tour: 0\n","  Edge (0, 18):\n","     Weight: 0.4857390315454929\n","     Tour: 0\n","  Edge (0, 19):\n","     Weight: 0.2955332394593224\n","     Tour: 0\n","  Edge (1, 2):\n","     Weight: 0.6148965694180403\n","     Tour: 0\n","  Edge (1, 3):\n","     Weight: 0.458726401538421\n","     Tour: 0\n","  Edge (1, 4):\n","     Weight: 0.35637320892343344\n","     Tour: 1\n","  Edge (1, 5):\n","     Weight: 0.6032864976885546\n","     Tour: 0\n","  Edge (1, 6):\n","     Weight: 0.6569915301709606\n","     Tour: 0\n","  Edge (1, 7):\n","     Weight: 0.9207746398930378\n","     Tour: 0\n","  Edge (1, 8):\n","     Weight: 0.746742011300412\n","     Tour: 0\n","  Edge (1, 9):\n","     Weight: 0.5810402333348532\n","     Tour: 0\n","  Edge (1, 10):\n","     Weight: 0.16704392462309525\n","     Tour: 0\n","  Edge (1, 11):\n","     Weight: 0.44648016447297073\n","     Tour: 0\n","  Edge (1, 12):\n","     Weight: 0.7422384454019971\n","     Tour: 0\n","  Edge (1, 13):\n","     Weight: 0.9087485603102635\n","     Tour: 0\n","  Edge (1, 14):\n","     Weight: 0.5479091406494869\n","     Tour: 0\n","  Edge (1, 15):\n","     Weight: 0.14178198392466582\n","     Tour: 1\n","  Edge (1, 16):\n","     Weight: 0.754354006043937\n","     Tour: 0\n","  Edge (1, 17):\n","     Weight: 0.6438862448532572\n","     Tour: 0\n","  Edge (1, 18):\n","     Weight: 0.7726546814458304\n","     Tour: 0\n","  Edge (1, 19):\n","     Weight: 0.5987646096934333\n","     Tour: 0\n","  Edge (2, 3):\n","     Weight: 0.15622130264510733\n","     Tour: 0\n","  Edge (2, 4):\n","     Weight: 0.2841510683911888\n","     Tour: 0\n","  Edge (2, 5):\n","     Weight: 0.5519190450546716\n","     Tour: 0\n","  Edge (2, 6):\n","     Weight: 0.13946205995874017\n","     Tour: 0\n","  Edge (2, 7):\n","     Weight: 0.3114220898670106\n","     Tour: 0\n","  Edge (2, 8):\n","     Weight: 0.4194690047798088\n","     Tour: 0\n","  Edge (2, 9):\n","     Weight: 0.08856321635783988\n","     Tour: 1\n","  Edge (2, 10):\n","     Weight: 0.5083743055689474\n","     Tour: 0\n","  Edge (2, 11):\n","     Weight: 0.2644009954540205\n","     Tour: 0\n","  Edge (2, 12):\n","     Weight: 0.2208301469437315\n","     Tour: 0\n","  Edge (2, 13):\n","     Weight: 0.4003621671541578\n","     Tour: 0\n","  Edge (2, 14):\n","     Weight: 0.09093880543328159\n","     Tour: 1\n","  Edge (2, 15):\n","     Weight: 0.6278926750270484\n","     Tour: 0\n","  Edge (2, 16):\n","     Weight: 0.14517438585231934\n","     Tour: 0\n","  Edge (2, 17):\n","     Weight: 0.49907142344556654\n","     Tour: 0\n","  Edge (2, 18):\n","     Weight: 0.34060003464189553\n","     Tour: 0\n","  Edge (2, 19):\n","     Weight: 0.3852352221449024\n","     Tour: 0\n","  Edge (3, 4):\n","     Weight: 0.14654472382192782\n","     Tour: 0\n","  Edge (3, 5):\n","     Weight: 0.4946628652419162\n","     Tour: 0\n","  Edge (3, 6):\n","     Weight: 0.2312084560472005\n","     Tour: 0\n","  Edge (3, 7):\n","     Weight: 0.46429696895897604\n","     Tour: 0\n","  Edge (3, 8):\n","     Weight: 0.4453880485781254\n","     Tour: 0\n","  Edge (3, 9):\n","     Weight: 0.14324743187115518\n","     Tour: 0\n","  Edge (3, 10):\n","     Weight: 0.357006300672558\n","     Tour: 0\n","  Edge (3, 11):\n","     Weight: 0.17313884874554414\n","     Tour: 0\n","  Edge (3, 12):\n","     Weight: 0.3256331892473202\n","     Tour: 0\n","  Edge (3, 13):\n","     Weight: 0.5098507108265369\n","     Tour: 0\n","  Edge (3, 14):\n","     Weight: 0.10192800337320708\n","     Tour: 1\n","  Edge (3, 15):\n","     Weight: 0.4760316956166869\n","     Tour: 0\n","  Edge (3, 16):\n","     Weight: 0.2982239590456468\n","     Tour: 0\n","  Edge (3, 17):\n","     Weight: 0.4650265877604502\n","     Tour: 0\n","  Edge (3, 18):\n","     Weight: 0.40529952122582097\n","     Tour: 0\n","  Edge (3, 19):\n","     Weight: 0.3641842557466924\n","     Tour: 0\n","  Edge (4, 5):\n","     Weight: 0.5764321626357953\n","     Tour: 0\n","  Edge (4, 6):\n","     Weight: 0.30133829128093664\n","     Tour: 0\n","  Edge (4, 7):\n","     Weight: 0.5950103618814667\n","     Tour: 0\n","  Edge (4, 8):\n","     Weight: 0.5770449832745134\n","     Tour: 0\n","  Edge (4, 9):\n","     Weight: 0.2307340037832632\n","     Tour: 0\n","  Edge (4, 10):\n","     Weight: 0.3046349275334078\n","     Tour: 0\n","  Edge (4, 11):\n","     Weight: 0.26810007977040523\n","     Tour: 0\n","  Edge (4, 12):\n","     Weight: 0.3859450475320259\n","     Tour: 0\n","  Edge (4, 13):\n","     Weight: 0.5561153892125273\n","     Tour: 0\n","  Edge (4, 14):\n","     Weight: 0.24804828262824546\n","     Tour: 0\n","  Edge (4, 15):\n","     Weight: 0.41247528818868645\n","     Tour: 0\n","  Edge (4, 16):\n","     Weight: 0.410375847856154\n","     Tour: 0\n","  Edge (4, 17):\n","     Weight: 0.5656186289094377\n","     Tour: 0\n","  Edge (4, 18):\n","     Weight: 0.5483723633197157\n","     Tour: 0\n","  Edge (4, 19):\n","     Weight: 0.30210799803116456\n","     Tour: 0\n","  Edge (5, 6):\n","     Weight: 0.6867560124051679\n","     Tour: 0\n","  Edge (5, 7):\n","     Weight: 0.6992915692243714\n","     Tour: 0\n","  Edge (5, 8):\n","     Weight: 0.27073049472112015\n","     Tour: 0\n","  Edge (5, 9):\n","     Weight: 0.6078062084716456\n","     Tour: 0\n","  Edge (5, 10):\n","     Weight: 0.43958977527759663\n","     Tour: 0\n","  Edge (5, 11):\n","     Weight: 0.32199052710954257\n","     Tour: 1\n","  Edge (5, 12):\n","     Weight: 0.7727326567888985\n","     Tour: 0\n","  Edge (5, 13):\n","     Weight: 0.9501826066747174\n","     Tour: 0\n","  Edge (5, 14):\n","     Weight: 0.46911196324102344\n","     Tour: 0\n","  Edge (5, 15):\n","     Weight: 0.4935936115373682\n","     Tour: 0\n","  Edge (5, 16):\n","     Weight: 0.6639435819391838\n","     Tour: 0\n","  Edge (5, 17):\n","     Weight: 0.08842284642269631\n","     Tour: 1\n","  Edge (5, 18):\n","     Weight: 0.3771405718250126\n","     Tour: 0\n","  Edge (5, 19):\n","     Weight: 0.8562970048150594\n","     Tour: 0\n","  Edge (6, 7):\n","     Weight: 0.3452299871310383\n","     Tour: 0\n","  Edge (6, 8):\n","     Weight: 0.5566916991250165\n","     Tour: 0\n","  Edge (6, 9):\n","     Weight: 0.08818713565270636\n","     Tour: 1\n","  Edge (6, 10):\n","     Weight: 0.5806051325658653\n","     Tour: 0\n","  Edge (6, 11):\n","     Weight: 0.38358592867555963\n","     Tour: 0\n","  Edge (6, 12):\n","     Weight: 0.09446322848406911\n","     Tour: 0\n","  Edge (6, 13):\n","     Weight: 0.27914978407080576\n","     Tour: 0\n","  Edge (6, 14):\n","     Weight: 0.2178340373451969\n","     Tour: 0\n","  Edge (6, 15):\n","     Weight: 0.6973941311815144\n","     Tour: 0\n","  Edge (6, 16):\n","     Weight: 0.1437315155664361\n","     Tour: 0\n","  Edge (6, 17):\n","     Weight: 0.6372490513538306\n","     Tour: 0\n","  Edge (6, 18):\n","     Weight: 0.4701840720104889\n","     Tour: 0\n","  Edge (6, 19):\n","     Weight: 0.2774232612572184\n","     Tour: 1\n","  Edge (7, 8):\n","     Weight: 0.45952904895181307\n","     Tour: 0\n","  Edge (7, 9):\n","     Weight: 0.37417400645996296\n","     Tour: 0\n","  Edge (7, 10):\n","     Weight: 0.7992567869828283\n","     Tour: 0\n","  Edge (7, 11):\n","     Weight: 0.5148673440983987\n","     Tour: 0\n","  Edge (7, 12):\n","     Weight: 0.33571626255030856\n","     Tour: 0\n","  Edge (7, 13):\n","     Weight: 0.4026101124667492\n","     Tour: 0\n","  Edge (7, 14):\n","     Weight: 0.37340467136695177\n","     Tour: 0\n","  Edge (7, 15):\n","     Weight: 0.9174698538239648\n","     Tour: 0\n","  Edge (7, 16):\n","     Weight: 0.20177465871599579\n","     Tour: 1\n","  Edge (7, 17):\n","     Weight: 0.6195648253244966\n","     Tour: 0\n","  Edge (7, 18):\n","     Weight: 0.33917612945209147\n","     Tour: 1\n","  Edge (7, 19):\n","     Weight: 0.6162194325540812\n","     Tour: 0\n","  Edge (8, 9):\n","     Weight: 0.500606236365931\n","     Tour: 0\n","  Edge (8, 10):\n","     Weight: 0.5829012393087726\n","     Tour: 0\n","  Edge (8, 11):\n","     Weight: 0.3226682580193532\n","     Tour: 0\n","  Edge (8, 12):\n","     Weight: 0.6236465117971378\n","     Tour: 0\n","  Edge (8, 13):\n","     Weight: 0.7794753363995585\n","     Tour: 0\n","  Edge (8, 14):\n","     Weight: 0.3687755686215689\n","     Tour: 0\n","  Edge (8, 15):\n","     Weight: 0.6744208504349039\n","     Tour: 0\n","  Edge (8, 16):\n","     Weight: 0.48341874284217323\n","     Tour: 0\n","  Edge (8, 17):\n","     Weight: 0.1823906358666875\n","     Tour: 1\n","  Edge (8, 18):\n","     Weight: 0.12039747445267121\n","     Tour: 1\n","  Edge (8, 19):\n","     Weight: 0.7920456502968736\n","     Tour: 0\n","  Edge (9, 10):\n","     Weight: 0.4958159010103946\n","     Tour: 0\n","  Edge (9, 11):\n","     Weight: 0.2981604547970567\n","     Tour: 0\n","  Edge (9, 12):\n","     Weight: 0.18263885255286078\n","     Tour: 0\n","  Edge (9, 13):\n","     Weight: 0.3672998819800728\n","     Tour: 0\n","  Edge (9, 14):\n","     Weight: 0.14074192147940914\n","     Tour: 0\n","  Edge (9, 15):\n","     Weight: 0.6136048694347368\n","     Tour: 0\n","  Edge (9, 16):\n","     Weight: 0.1807984883622037\n","     Tour: 0\n","  Edge (9, 17):\n","     Weight: 0.5635976733439557\n","     Tour: 0\n","  Edge (9, 18):\n","     Weight: 0.4275922503419513\n","     Tour: 0\n","  Edge (9, 19):\n","     Weight: 0.2972159394392491\n","     Tour: 0\n","  Edge (10, 11):\n","     Weight: 0.29767923348870867\n","     Tour: 1\n","  Edge (10, 12):\n","     Weight: 0.6728443418750315\n","     Tour: 0\n","  Edge (10, 13):\n","     Weight: 0.8518446381557372\n","     Tour: 0\n","  Edge (10, 14):\n","     Weight: 0.42882230173921154\n","     Tour: 0\n","  Edge (10, 15):\n","     Weight: 0.11952991870231995\n","     Tour: 1\n","  Edge (10, 16):\n","     Weight: 0.6531686692237917\n","     Tour: 0\n","  Edge (10, 17):\n","     Weight: 0.4770670662090856\n","     Tour: 0\n","  Edge (10, 18):\n","     Weight: 0.6168640222169508\n","     Tour: 0\n","  Edge (10, 19):\n","     Weight: 0.5961301720109755\n","     Tour: 0\n","  Edge (11, 12):\n","     Weight: 0.47581620562438115\n","     Tour: 0\n","  Edge (11, 13):\n","     Weight: 0.6599029483947126\n","     Tour: 0\n","  Edge (11, 14):\n","     Weight: 0.17346768130254947\n","     Tour: 0\n","  Edge (11, 15):\n","     Weight: 0.41048539737715684\n","     Tour: 0\n","  Edge (11, 16):\n","     Weight: 0.4025683785940153\n","     Tour: 0\n","  Edge (11, 17):\n","     Weight: 0.29925677077431195\n","     Tour: 0\n","  Edge (11, 18):\n","     Weight: 0.3274947351745373\n","     Tour: 0\n","  Edge (11, 19):\n","     Weight: 0.5346097241040995\n","     Tour: 0\n","  Edge (12, 13):\n","     Weight: 0.18490797189553923\n","     Tour: 1\n","  Edge (12, 14):\n","     Weight: 0.3065099771993463\n","     Tour: 0\n","  Edge (12, 15):\n","     Weight: 0.7887404243083697\n","     Tour: 0\n","  Edge (12, 16):\n","     Weight: 0.15629069658405714\n","     Tour: 1\n","  Edge (12, 17):\n","     Weight: 0.7187869230155136\n","     Tour: 0\n","  Edge (12, 18):\n","     Weight: 0.5268902682284917\n","     Tour: 0\n","  Edge (12, 19):\n","     Weight: 0.28846075399036875\n","     Tour: 0\n","  Edge (13, 14):\n","     Weight: 0.48887714561053647\n","     Tour: 0\n","  Edge (13, 15):\n","     Weight: 0.9657246855588165\n","     Tour: 0\n","  Edge (13, 16):\n","     Weight: 0.2962429306808471\n","     Tour: 0\n","  Edge (13, 17):\n","     Weight: 0.8913669046263939\n","     Tour: 0\n","  Edge (13, 18):\n","     Weight: 0.6721854655144677\n","     Tour: 0\n","  Edge (13, 19):\n","     Weight: 0.3719877587298442\n","     Tour: 1\n","  Edge (14, 15):\n","     Weight: 0.5480609545208327\n","     Tour: 0\n","  Edge (14, 16):\n","     Weight: 0.2321206572622659\n","     Tour: 0\n","  Edge (14, 17):\n","     Weight: 0.42288927202931514\n","     Tour: 0\n","  Edge (14, 18):\n","     Weight: 0.3126013860373729\n","     Tour: 0\n","  Edge (14, 19):\n","     Weight: 0.4234389913230374\n","     Tour: 0\n","  Edge (15, 16):\n","     Weight: 0.7726413301352619\n","     Tour: 0\n","  Edge (15, 17):\n","     Weight: 0.5469248197512611\n","     Tour: 0\n","  Edge (15, 18):\n","     Weight: 0.7204237265004912\n","     Tour: 0\n","  Edge (15, 19):\n","     Weight: 0.6911317266141075\n","     Tour: 0\n","  Edge (16, 17):\n","     Weight: 0.599767667597168\n","     Tour: 0\n","  Edge (16, 18):\n","     Weight: 0.3787620993736398\n","     Tour: 0\n","  Edge (16, 19):\n","     Weight: 0.41838423486864734\n","     Tour: 0\n","  Edge (17, 18):\n","     Weight: 0.2912935061526579\n","     Tour: 0\n","  Edge (17, 19):\n","     Weight: 0.8291779696877807\n","     Tour: 0\n","  Edge (18, 19):\n","     Weight: 0.7246549985661137\n","     Tour: 0\n"]}],"source":["# Describe the edge attributes tour and weight\n","\n","# Extract the graph and tour\n","graph = dummy[0][0]  # The networkx Graph object\n","tour = dummy[0][1]   # The tour as a list of nodes\n","\n","# Inspect edges with attributes\n","print(\"Edges and attributes:\")\n","for u, v, data in graph.edges(data=True):\n","    print(f\"  Edge ({u}, {v}):\")\n","    print(f\"     Weight: {data.get('weight', 'Not found')}\")\n","    print(f\"     Tour: {data.get('tour', 'Not found')}\")"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-12-26T14:44:18.921064Z","iopub.status.busy":"2024-12-26T14:44:18.920842Z","iopub.status.idle":"2024-12-26T14:44:18.933430Z","shell.execute_reply":"2024-12-26T14:44:18.932649Z","shell.execute_reply.started":"2024-12-26T14:44:18.921040Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Nodes and attributes:\n","  Node 0:\n","     Position: (0.6049077053425551, 0.5748590937018008)\n","  Node 1:\n","     Position: (0.38474987528197846, 0.9428085200806016)\n","  Node 2:\n","     Position: (0.6102491981278754, 0.3707527129445174)\n","  Node 3:\n","     Position: (0.5497610140601452, 0.514788385568776)\n","  Node 4:\n","     Position: (0.5941533303116413, 0.6544475361385552)\n","  Node 5:\n","     Position: (0.06187381797691738, 0.433195284467101)\n","  Node 6:\n","     Position: (0.7475717305758963, 0.3950876312718402)\n","  Node 7:\n","     Position: (0.6548530739834322, 0.06254140180263457)\n","  Node 8:\n","     Position: (0.2210796367473482, 0.2142238067774731)\n","  Node 9:\n","     Position: (0.6696714621150585, 0.4364218673039507)\n","  Node 10:\n","     Position: (0.3206284506117195, 0.7885615893113229)\n","  Node 11:\n","     Position: (0.37760295594024584, 0.4963855605324464)\n","  Node 12:\n","     Position: (0.8300002368321365, 0.3489482457969727)\n","  Node 13:\n","     Position: (0.9983722301898076, 0.2725163812162502)\n","  Node 14:\n","     Position: (0.5306200040273271, 0.4146737532387711)\n","  Node 15:\n","     Position: (0.2540580284004623, 0.8878378722372976)\n","  Node 16:\n","     Position: (0.7024553839343133, 0.2586205516051998)\n","  Node 17:\n","     Position: (0.11129635562701035, 0.35987398782201374)\n","  Node 18:\n","     Position: (0.33376928628552816, 0.1718375502602505)\n","  Node 19:\n","     Position: (0.8952647398936215, 0.6299289412776933)\n"]}],"source":["# Inspect the node attribute pos\n","print(\"\\nNodes and attributes:\")\n","for node, data in graph.nodes(data=True):\n","    print(f\"  Node {node}:\")\n","    print(f\"     Position: {data.get('pos', 'Not found')}\")"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-12-26T14:44:18.935173Z","iopub.status.busy":"2024-12-26T14:44:18.934509Z","iopub.status.idle":"2024-12-26T14:44:18.942111Z","shell.execute_reply":"2024-12-26T14:44:18.941439Z","shell.execute_reply.started":"2024-12-26T14:44:18.935133Z"},"trusted":true},"outputs":[],"source":["# # Analyze the tour\n","# print(\"\\nTour edges:\")\n","# tour_edges = [(tour[i], tour[i+1]) for i in range(len(tour) - 1)]\n","# for u, v in tour_edges:\n","#     if graph.has_edge(u, v):\n","#         print(f\"   Edge ({u}, {v}) exists with weight {graph[u][v].get('weight', 'Not found')}.\")\n","#     else:\n","#         print(f\"   Edge ({u}, {v}) does not exist in the graph.\")"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-12-26T14:56:57.739609Z","iopub.status.busy":"2024-12-26T14:56:57.738959Z","iopub.status.idle":"2024-12-26T14:56:57.801972Z","shell.execute_reply":"2024-12-26T14:56:57.801074Z","shell.execute_reply.started":"2024-12-26T14:56:57.739575Z"},"trusted":true},"outputs":[],"source":["torch.manual_seed(0)\n","DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-12-26T14:57:00.005255Z","iopub.status.busy":"2024-12-26T14:57:00.004399Z","iopub.status.idle":"2024-12-26T14:57:00.011402Z","shell.execute_reply":"2024-12-26T14:57:00.010429Z","shell.execute_reply.started":"2024-12-26T14:57:00.005216Z"},"trusted":true},"outputs":[],"source":["# Implement a dataset class. Focus on the getitem method to return:\n","# – X: A tensor of node coordinates with size 20 × 2.\n","# – y: A tour starting from 0 and ending with 0.\n","\n","class GraphDataset(Dataset):\n","    def __init__(self, data):\n","        \"\"\"\n","        Args:\n","            data: A list of tuples where each tuple contains:\n","                  - A networkx.Graph object\n","                  - A tour (list of node indices)\n","        \"\"\"\n","        self.data = data\n","\n","    def __len__(self):\n","        \"\"\"\n","        Returns the number of instances in the dataset.\n","        \"\"\"\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        \"\"\"\n","        Returns:\n","            X: A tensor of node coordinates with size 20 × 2.\n","            y: A tensor representing the tour, starting and ending at 0.\n","        \"\"\"\n","        # Extract the graph and tour\n","        graph, tour = self.data[idx]\n","\n","        # Get node positions as a 2D array\n","        pos = nx.get_node_attributes(graph, 'pos')  # Dictionary {node: (x, y)}\n","        if not pos:\n","            raise ValueError(f\"Graph at index {idx} is missing node positions ('pos').\")\n","\n","        # Ensure nodes are sorted by their index (important for consistent tensor order)\n","        sorted_positions = [pos[node] for node in sorted(graph.nodes())]\n","        \n","        # Convert positions to a tensor of shape (20, 2)\n","        X = torch.tensor(sorted_positions, dtype=torch.float32)\n","\n","        # Convert the tour to a tensor\n","        y = torch.tensor(tour, dtype=torch.long)\n","\n","        return X, y"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-12-26T14:57:02.748377Z","iopub.status.busy":"2024-12-26T14:57:02.748026Z","iopub.status.idle":"2024-12-26T14:57:02.753687Z","shell.execute_reply":"2024-12-26T14:57:02.752824Z","shell.execute_reply.started":"2024-12-26T14:57:02.748346Z"},"trusted":true},"outputs":[],"source":["# Create Dataset objects for training, validation, and testing, along with their respective Dataloader\n","dataset = GraphDataset(dummy)\n","train_dataset, val_dataset, test_dataset = random_split(dataset, [0.8, 0.1, 0.1])\n","\n","batch_size = 32\n","\n","trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","valloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n","testloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"]},{"cell_type":"markdown","metadata":{},"source":["## Model"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-12-26T14:57:05.196892Z","iopub.status.busy":"2024-12-26T14:57:05.196519Z","iopub.status.idle":"2024-12-26T14:57:05.207479Z","shell.execute_reply":"2024-12-26T14:57:05.206661Z","shell.execute_reply.started":"2024-12-26T14:57:05.196859Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch import Tensor\n","\n","class PositionalEncoding(nn.Module):\n","    def __init__(self,emb_size: int, dropout: float, maxlen: int = 5000):\n","        super(PositionalEncoding, self).__init__()\n","\n","        pos_embedding = torch.zeros((maxlen, emb_size))\n","        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n","        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)   \n","        \n","        pos_embedding[:, 0::2] = torch.sin(pos * den)\n","        pos_embedding[:, 1::2] = torch.cos(pos * den)\n","        pos_embedding = pos_embedding.unsqueeze(-2)\n","\n","        self.dropout = nn.Dropout(dropout)\n","        self.register_buffer('pos_embedding', pos_embedding)\n","\n","    def forward(self, token_embedding: Tensor):\n","        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n","\n","class TSPTransformer(nn.Module):\n","    def __init__(self, n, num_encoder, num_decoder, de, dd, n_head, dropout):\n","        super(TSPTransformer, self).__init__()\n","        # Encoder\n","        self.linear1 = nn.Linear(2, de)\n","        encoder_layer = nn.TransformerEncoderLayer(d_model=de, nhead=n_head) # d_model (int) – the number of expected features in the input (required).\n","        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_encoder) # stack of n encoder layers\n","        self.linear2 = nn.Linear(de, dd)\n","        \n","        # Decoder\n","        self.embedding = nn.Embedding(n, dd)\n","        self.posEncoding = PositionalEncoding(dd, dropout)\n","        decoder_layer = nn.TransformerDecoderLayer(d_model=dd, nhead=n_head)\n","        self.decoder = nn.TransformerDecoder(decoder_layer, num_layers=num_decoder)\n","        self.ffnn = nn.Linear(dd, n)\n","\n","    def forward(self, src, trg):\n","        # Encoding\n","        src = self.linear1(src)\n","        src = self.encoder(src)\n","        src = self.linear2(src)\n","        \n","        # Decoding\n","        trg = self.embedding(trg)\n","        trg = self.posEncoding(trg)\n","        output = self.decoder(trg, src)\n","        output = self.ffnn(output)\n","        return output"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-12-26T14:57:07.736185Z","iopub.status.busy":"2024-12-26T14:57:07.735392Z","iopub.status.idle":"2024-12-26T14:57:08.181361Z","shell.execute_reply":"2024-12-26T14:57:08.180482Z","shell.execute_reply.started":"2024-12-26T14:57:07.736148Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[0., -inf, -inf, -inf, -inf],\n","        [0., 0., -inf, -inf, -inf],\n","        [0., 0., 0., -inf, -inf],\n","        [0., 0., 0., 0., -inf],\n","        [0., 0., 0., 0., 0.]], device='cuda:0')\n"]}],"source":["def generate_square_subsequent_mask(sz):\n","    ## Decoder mask\n","    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n","    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n","    return mask\n","\n","\n","def create_mask(src, tgt):\n","    src_seq_len = src.shape[0]\n","    tgt_seq_len = tgt.shape[0]\n","\n","    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n","    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n","\n","    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n","    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n","    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask\n","\n","# Just to have an idea of what it looks like:\n","print(generate_square_subsequent_mask(5))"]},{"cell_type":"markdown","metadata":{},"source":["$n$ = num di nodes -> Each TSP instance has exactly 20 nodes, and the input consists of their 2D coordinates.\n","\n","$de$ = size of the internal rapresentation of the input coordinates\n","       2 feature per node -> small values like 16, 32, 64\n","\n","$dd$ = size of intermediate representation\n","     y is a sequence of discrete node indeces, typical equal to de but also higher\n","\n","$Ne$ = num encoeer layers -> 2,4,6\n","\n","$Nd$ = num decoder layers -> equal to Ne but also higher"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-12-26T14:57:27.279846Z","iopub.status.busy":"2024-12-26T14:57:27.279111Z","iopub.status.idle":"2024-12-26T14:57:27.355349Z","shell.execute_reply":"2024-12-26T14:57:27.354586Z","shell.execute_reply.started":"2024-12-26T14:57:27.279810Z"},"trusted":true},"outputs":[],"source":["import math\n","\n","n = 20\n","n_enc = 4\n","n_dec = 4\n","de = 32\n","dd = 64\n","N_HEAD = 8\n","DROPOUT = 0.1\n","\n","TSPmodel = TSPTransformer(n, n_enc, n_dec, de, dd, N_HEAD, DROPOUT)\n","\n","TSPmodel = TSPmodel.to(DEVICE)"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-12-26T14:57:29.756397Z","iopub.status.busy":"2024-12-26T14:57:29.755691Z","iopub.status.idle":"2024-12-26T14:57:30.578219Z","shell.execute_reply":"2024-12-26T14:57:30.577234Z","shell.execute_reply.started":"2024-12-26T14:57:29.756360Z"},"trusted":true},"outputs":[],"source":["# hyperparameters\n","loss_fn = torch.nn.CrossEntropyLoss()\n","\n","optimizer = torch.optim.Adam(TSPmodel.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"]},{"cell_type":"markdown","metadata":{},"source":["## Training"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-12-26T15:03:23.694591Z","iopub.status.busy":"2024-12-26T15:03:23.693971Z","iopub.status.idle":"2024-12-26T15:03:23.698705Z","shell.execute_reply":"2024-12-26T15:03:23.697817Z","shell.execute_reply.started":"2024-12-26T15:03:23.694547Z"},"trusted":true},"outputs":[],"source":["import warnings\n","from timeit import default_timer as timer\n","import math\n","from torch.utils.data import DataLoader"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-12-26T15:03:25.603406Z","iopub.status.busy":"2024-12-26T15:03:25.602581Z","iopub.status.idle":"2024-12-26T15:03:25.613558Z","shell.execute_reply":"2024-12-26T15:03:25.612779Z","shell.execute_reply.started":"2024-12-26T15:03:25.603370Z"},"trusted":true},"outputs":[],"source":["# Function for training a single epoch\n","def train_epoch(model, optimizer, trainloader):\n","    model.train()\n","    losses = 0\n","\n","    for src, tgt in trainloader:\n","        src = src.to(DEVICE)  # Node coordinates (input to the encoder)\n","        tgt = tgt.to(DEVICE)  # Tour indices (target sequence for the decoder)\n","\n","        tgt_input = tgt[:, :-1]  # Input to the decoder (shifted by one token)\n","\n","        optimizer.zero_grad()\n","\n","        # Generate masks for attention\n","        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n","\n","        # Forward pass\n","        logits = model(src, tgt_input, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask, src_padding_mask)\n","\n","        tgt_out = tgt[:, 1:]  # Target for loss computation (shifted by one token)\n","        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n","        loss.backward()\n","\n","        # Update weights\n","        optimizer.step()\n","        losses += loss.item()\n","\n","    return losses / len(trainloader)\n","\n","\n","# Function for evaluation\n","def evaluate(model, valloader):\n","    model.eval()\n","    losses = 0\n","\n","    with torch.no_grad():\n","        for src, tgt in valloader:\n","            src = src.to(DEVICE)  # Node coordinates (input to the encoder)\n","            tgt = tgt.to(DEVICE)  # Tour indices (target sequence for the decoder)\n","\n","            tgt_input = tgt[:, :-1]  # Input to the decoder (shifted by one token)\n","\n","            # Generate masks for attention\n","            src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n","\n","            # Forward pass\n","            logits = model(src, tgt_input, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask, src_padding_mask)\n","\n","            tgt_out = tgt[:, 1:]  # Target for loss computation (shifted by one token)\n","            loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n","            losses += loss.item()\n","\n","    avg_loss = losses / len(valloader)\n","    perplexity = math.exp(avg_loss)\n","    return avg_loss, perplexity\n","\n","\n","# Evaluate a single TSP instance\n","def evaluate_single_sentence(model, example_idx):\n","    model.eval()\n","\n","    with torch.no_grad():\n","        src, tgt = dataset[example_idx]  # Get a single example from the dataset\n","        src = src.to(DEVICE).unsqueeze(0)  # Add batch dimension for the model\n","        tgt = tgt.to(DEVICE).unsqueeze(0)  # Add batch dimension for the model\n","\n","        tgt_input = tgt[:, :-1]  # Input to the decoder (shifted by one token)\n","\n","        # Generate masks for attention\n","        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n","\n","        # Forward pass\n","        logits = model(src, tgt_input, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask, src_padding_mask)\n","\n","        predicted_tour = logits.argmax(dim=-1)  # Get predicted tour indices\n","        return src.squeeze(0).cpu().tolist(), tgt.squeeze(0).cpu().tolist(), predicted_tour.squeeze(0).cpu().tolist()\n"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-12-26T15:03:28.700389Z","iopub.status.busy":"2024-12-26T15:03:28.699637Z","iopub.status.idle":"2024-12-26T15:03:28.760263Z","shell.execute_reply":"2024-12-26T15:03:28.759232Z","shell.execute_reply.started":"2024-12-26T15:03:28.700350Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Untrained model\n"]},{"ename":"NameError","evalue":"name 'PAD_IDX' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[28], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m val_losses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUntrained model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m source, target, translation \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_single_sentence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTSPmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSource (node coordinates): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msource\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget (optimal tour): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n","Cell \u001b[0;32mIn[27], line 70\u001b[0m, in \u001b[0;36mevaluate_single_sentence\u001b[0;34m(model, example_idx)\u001b[0m\n\u001b[1;32m     67\u001b[0m tgt_input \u001b[38;5;241m=\u001b[39m tgt[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# Input to the decoder (shifted by one token)\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Generate masks for attention\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m src_mask, tgt_mask, src_padding_mask, tgt_padding_mask \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m     73\u001b[0m logits \u001b[38;5;241m=\u001b[39m model(src, tgt_input, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask, src_padding_mask)\n","Cell \u001b[0;32mIn[18], line 15\u001b[0m, in \u001b[0;36mcreate_mask\u001b[0;34m(src, tgt)\u001b[0m\n\u001b[1;32m     12\u001b[0m tgt_mask \u001b[38;5;241m=\u001b[39m generate_square_subsequent_mask(tgt_seq_len)\n\u001b[1;32m     13\u001b[0m src_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros((src_seq_len, src_seq_len),device\u001b[38;5;241m=\u001b[39mDEVICE)\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mbool)\n\u001b[0;32m---> 15\u001b[0m src_padding_mask \u001b[38;5;241m=\u001b[39m (src \u001b[38;5;241m==\u001b[39m \u001b[43mPAD_IDX\u001b[49m)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     16\u001b[0m tgt_padding_mask \u001b[38;5;241m=\u001b[39m (tgt \u001b[38;5;241m==\u001b[39m PAD_IDX)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m src_mask, tgt_mask, src_padding_mask, tgt_padding_mask\n","\u001b[0;31mNameError\u001b[0m: name 'PAD_IDX' is not defined"]}],"source":["warnings.filterwarnings(\"ignore\")\n","\n","# Training configuration\n","NUM_EPOCHS = 10\n","training_losses = []\n","val_losses = []\n","\n","print(\"Untrained model\")\n","source, target, translation = evaluate_single_sentence(TSPmodel, 0)\n","print(f\"Source (node coordinates): {source}\")\n","print(f\"Target (optimal tour): {target}\")\n","print(f\"Translation (predicted tour): {translation}\")\n","print(\"\\n\\n\")\n","\n","print(\"*\" * 20)\n","print(\"Training\")\n","print(\"*\" * 20)\n","\n","# Training loop\n","for epoch in range(1, NUM_EPOCHS + 1):\n","    start_time = timer()\n","    \n","    # Train for one epoch\n","    train_loss = train_epoch(TSPmodel, optimizer, trainloader)\n","    end_time = timer()\n","    \n","    # Evaluate on validation data\n","    val_loss, perplexity = evaluate(TSPmodel, valloader)\n","    \n","    print(f\"Epoch: {epoch}\")\n","    print(f\"Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, Perplexity: {perplexity:.3f}\")\n","    print(f\"Epoch time = {(end_time - start_time):.3f}s\")\n","    \n","    # Log losses\n","    training_losses.append(train_loss)\n","    val_losses.append(val_loss)\n","    \n","    # Evaluate a single example\n","    source, target, translation = evaluate_single_sentence(TSPmodel, 0)\n","    print(f\"Source (node coordinates): {source}\")\n","    print(f\"Target (optimal tour): {target}\")\n","    print(f\"Translation (predicted tour): {translation}\")\n","    print(\"\\n\\n\")"]},{"cell_type":"markdown","metadata":{},"source":["### Training WITHOUT gradient accumulation"]},{"cell_type":"markdown","metadata":{},"source":["### Training WITH gradient accumulation"]},{"cell_type":"markdown","metadata":{},"source":["## Testing"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":6323224,"sourceId":10227445,"sourceType":"datasetVersion"}],"dockerImageVersionId":30804,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
