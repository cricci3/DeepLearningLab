{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10227445,"sourceType":"datasetVersion","datasetId":6323224},{"sourceId":221585,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":188999,"modelId":211005}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# CLAUDIO RICCI","metadata":{}},{"cell_type":"markdown","source":"## Packages","metadata":{}},{"cell_type":"code","source":"import networkx as nx # For graphs\nimport pickle # For data parsing\nfrom networkx.algorithms.approximation import greedy_tsp # For approx TSP\nimport numpy as np\n\nimport torch\nfrom torch.utils.data import DataLoader, random_split, Dataset\nimport torch.nn as nn\nfrom torch.nn import Transformer\nfrom torch import Tensor\n\nimport warnings\nfrom timeit import default_timer as timer\nimport math\n\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-07T10:30:45.978273Z","iopub.execute_input":"2025-01-07T10:30:45.978589Z","iopub.status.idle":"2025-01-07T10:30:50.260086Z","shell.execute_reply.started":"2025-01-07T10:30:45.978549Z","shell.execute_reply":"2025-01-07T10:30:50.258901Z"},"ExecuteTime":{"end_time":"2024-12-05T09:31:30.777483Z","start_time":"2024-12-05T09:31:30.704856Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"## Helper functions","metadata":{}},{"cell_type":"code","source":"def tour_length(G, tour):\n    \"\"\"\n    Compute the length of a tour. A tour is a list having elments 0 and -1 equal\n    \"\"\"\n    assert tour[0] == tour[-1], \"Not valid tour\"\n    estimated = 0\n    n = G.number_of_nodes()\n    \n    for i in range(n):\n        estimated += G[tour[i]][tour[i + 1]]['weight']\n    return estimated\n\ndef greedy_algorithm(G):\n    \"\"\"\n    Run the value of the greedy approximation algorithm on graph G\n    \"\"\"\n    return tour_length(G, greedy_tsp(G, weight='weight'))\n\ndef random_tour(G, seed = 42):\n    \"\"\"\n    Return the value of a random tour\n    \"\"\"\n    np.random.seed(seed)\n    n = G.number_of_nodes()\n    tour = [0]\n    for i in range(1, n):\n        next_node = np.random.choice([j for j in range(n) if j not in tour])\n        tour.append(next_node)\n    tour.append(0)\n    return tour_length(G, tour)\n\ndef transformer_tsp(G, model, DEVICE = 'cpu'):\n    \"\"\"\n    Evaluate your (trained) model on G\n    \"\"\"\n    # Set the model in evaluation mode\n    model.eval()\n\n    # Note: number of edges is constant ed equal to n(n-1)/2\n    n = G.number_of_nodes()\n    \n    # Get node coordinates\n    attr = nx.get_node_attributes(G, 'pos')\n    x = []\n    for i in range(n):\n        x.append(torch.tensor(attr[i], dtype=torch.float32))\n\n    # From list of tensors to tensor 2d\n    x = torch.stack(x)    \n\n    tour = [0]\n    y = torch.tensor(tour, dtype=torch.long)\n    x = x.to(DEVICE).unsqueeze(0)\n    y = y.to(DEVICE).unsqueeze(0)\n\n    src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(x, y)\n    \n    out = model(x, y, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask, src_padding_mask)\n    \n    # Predict the next node\n    # out = transformer_model(x, y)\n    \n    # Loop until the tour is complete\n    while len(tour) < n:\n        _, idx = torch.topk(out, n, dim=2)\n        for i in range(n):\n            # Check if the node is already in the tour\n            if idx[0, 0, i] not in tour:\n                tour.append(idx[0, 0, i])\n                break\n        y = torch.tensor(tour)\n        y = y.to(DEVICE).unsqueeze(0)\n        out = transformer_model(x, y)\n\n        tgt_seq_len = y.shape[1]\n\n        tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n        tgt_padding_mask = torch.zeros((y.shape[0], tgt_seq_len), device=DEVICE).bool()\n        \n        out = model(x, y, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask, src_padding_mask)\n    \n    tour = [int(i) for i in tour] + [0] # Append the starting node (that is hard-coded to 0)\n    return tour_length(G, tour)\n\n\n\ndef gap(G, model = None, model_GA = None, random_seed = 42, device = 'cpu'):\n    \"\"\"\n    Compute the gap between the optimal solution on graph G and all the analyzed methods\n    \"\"\"\n\n        \n    # Optimal value (hard-coded in the graph)\n    TSP = sum([G[i][j]['weight']*G[i][j]['tour'] for (i, j) in G.edges()]) # Optimal\n\n    # Gaps dictionary\n    gaps = {'greedy' : 0, 'random' : 0, 'transformer_tsp': 0, 'transformer_tsp_acc_grad': 0}\n    gaps['greedy'] = 100* (greedy_algorithm(G) -  TSP) / TSP\n    gaps['random'] = 100 * (random_tour(G, random_seed) - TSP) / TSP\n    if model is not None:\n        gaps['transformer_tsp'] = 100 * (transformer_tsp(G, model, DEVICE=device) - TSP) / TSP\n    else:\n        gaps['transformer_tsp'] = float('inf') # In case you just train with GA\n        \n    if model_GA is not None:\n        gaps['transformer_tsp_acc_grad'] = 100 * (transformer_tsp(G, model_GA, DEVICE=device) - TSP) / TSP\n    else:\n        gaps['transformer_tsp_acc_grad'] = float('inf') # In case you just train without GA\n    return gaps    \n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T10:30:50.262473Z","iopub.execute_input":"2025-01-07T10:30:50.263224Z","iopub.status.idle":"2025-01-07T10:30:50.282338Z","shell.execute_reply.started":"2025-01-07T10:30:50.263175Z","shell.execute_reply":"2025-01-07T10:30:50.280845Z"},"ExecuteTime":{"end_time":"2024-12-05T09:31:30.806883Z","start_time":"2024-12-05T09:31:30.798896Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"## Dataset & Dataloader","metadata":{}},{"cell_type":"code","source":"# Load the dummy dataset, get a single data item and explain its Python type\n# with open('/kaggle/input/tspinstances/dummy_20_DLL_ass4.pkl', 'rb') as file:\n#    dummy = pickle.load(file)\n\nwith open('/kaggle/input/tspinstances/train_20_DLL_ass4.pkl', 'rb') as file:\n    train = pickle.load(file)\n\nprint(type(train)) # list\nprint('Type of a element of the dataset: ', type(train[0]))  # The type of the first object -> tuple\nprint('Type of the first item of the tuple: ', type(train[0][0]))  # The type of the first item of a tuple -> Graph\nprint('Type of the second item of the tuple: ', type(train[0][1]))  # The type of the first item of a tuple -> list\nprint(train[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T10:30:50.283777Z","iopub.execute_input":"2025-01-07T10:30:50.284475Z","iopub.status.idle":"2025-01-07T10:31:12.792632Z","shell.execute_reply.started":"2025-01-07T10:30:50.284436Z","shell.execute_reply":"2025-01-07T10:31:12.791435Z"}},"outputs":[{"name":"stdout","text":"<class 'list'>\nType of a element of the dataset:  <class 'tuple'>\nType of the first item of the tuple:  <class 'networkx.classes.graph.Graph'>\nType of the second item of the tuple:  <class 'list'>\n(<networkx.classes.graph.Graph object at 0x786076d29d50>, [0, 3, 14, 2, 9, 6, 19, 13, 12, 16, 7, 18, 8, 17, 5, 11, 10, 15, 1, 4, 0])\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"train[0][0].edges","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T10:31:12.795298Z","iopub.execute_input":"2025-01-07T10:31:12.795639Z","iopub.status.idle":"2025-01-07T10:31:12.805021Z","shell.execute_reply.started":"2025-01-07T10:31:12.795605Z","shell.execute_reply":"2025-01-07T10:31:12.803564Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"EdgeView([(0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (0, 8), (0, 9), (0, 10), (0, 11), (0, 12), (0, 13), (0, 14), (0, 15), (0, 16), (0, 17), (0, 18), (0, 19), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (1, 7), (1, 8), (1, 9), (1, 10), (1, 11), (1, 12), (1, 13), (1, 14), (1, 15), (1, 16), (1, 17), (1, 18), (1, 19), (2, 3), (2, 4), (2, 5), (2, 6), (2, 7), (2, 8), (2, 9), (2, 10), (2, 11), (2, 12), (2, 13), (2, 14), (2, 15), (2, 16), (2, 17), (2, 18), (2, 19), (3, 4), (3, 5), (3, 6), (3, 7), (3, 8), (3, 9), (3, 10), (3, 11), (3, 12), (3, 13), (3, 14), (3, 15), (3, 16), (3, 17), (3, 18), (3, 19), (4, 5), (4, 6), (4, 7), (4, 8), (4, 9), (4, 10), (4, 11), (4, 12), (4, 13), (4, 14), (4, 15), (4, 16), (4, 17), (4, 18), (4, 19), (5, 6), (5, 7), (5, 8), (5, 9), (5, 10), (5, 11), (5, 12), (5, 13), (5, 14), (5, 15), (5, 16), (5, 17), (5, 18), (5, 19), (6, 7), (6, 8), (6, 9), (6, 10), (6, 11), (6, 12), (6, 13), (6, 14), (6, 15), (6, 16), (6, 17), (6, 18), (6, 19), (7, 8), (7, 9), (7, 10), (7, 11), (7, 12), (7, 13), (7, 14), (7, 15), (7, 16), (7, 17), (7, 18), (7, 19), (8, 9), (8, 10), (8, 11), (8, 12), (8, 13), (8, 14), (8, 15), (8, 16), (8, 17), (8, 18), (8, 19), (9, 10), (9, 11), (9, 12), (9, 13), (9, 14), (9, 15), (9, 16), (9, 17), (9, 18), (9, 19), (10, 11), (10, 12), (10, 13), (10, 14), (10, 15), (10, 16), (10, 17), (10, 18), (10, 19), (11, 12), (11, 13), (11, 14), (11, 15), (11, 16), (11, 17), (11, 18), (11, 19), (12, 13), (12, 14), (12, 15), (12, 16), (12, 17), (12, 18), (12, 19), (13, 14), (13, 15), (13, 16), (13, 17), (13, 18), (13, 19), (14, 15), (14, 16), (14, 17), (14, 18), (14, 19), (15, 16), (15, 17), (15, 18), (15, 19), (16, 17), (16, 18), (16, 19), (17, 18), (17, 19), (18, 19)])"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# Describe the edge attributes tour and weight\n\n# Extract the graph and tour\ngraph = train[0][0]  # The networkx Graph object\ntour = train[0][1]   # The tour as a list of nodes\n\n# Inspect edges with attributes\n# print(\"Edges and attributes:\")\n# for u, v, data in graph.edges(data=True):\n#     print(f\"  Edge ({u}, {v}):\")\n#     print('     Weight: ', {data.get('weight', 'Not found')})\n#     print('     Tour: ',{data.get('tour', 'Not found')})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T10:31:12.806514Z","iopub.execute_input":"2025-01-07T10:31:12.807016Z","iopub.status.idle":"2025-01-07T10:31:12.829541Z","shell.execute_reply.started":"2025-01-07T10:31:12.806966Z","shell.execute_reply":"2025-01-07T10:31:12.828331Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Inspect the node attribute pos\n# print(\"\\nNodes and attributes:\")\n# for node, data in graph.nodes(data=True):\n#     print(f\"  Node {node}:\")\n#     print('     Position: ',{data.get('pos', 'Not found')})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T10:31:12.830859Z","iopub.execute_input":"2025-01-07T10:31:12.831244Z","iopub.status.idle":"2025-01-07T10:31:12.848052Z","shell.execute_reply.started":"2025-01-07T10:31:12.831209Z","shell.execute_reply":"2025-01-07T10:31:12.847005Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# # Analyze the tour\n# print(\"\\nTour edges:\")\n# tour_edges = [(tour[i], tour[i+1]) for i in range(len(tour) - 1)]\n# for u, v in tour_edges:\n#     if graph.has_edge(u, v):\n#         print(f\"   Edge ({u}, {v}) exists with weight {graph[u][v].get('weight', 'Not found')}.\")\n#     else:\n#         print(f\"   Edge ({u}, {v}) does not exist in the graph.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T10:31:12.849731Z","iopub.execute_input":"2025-01-07T10:31:12.850667Z","iopub.status.idle":"2025-01-07T10:31:12.862627Z","shell.execute_reply.started":"2025-01-07T10:31:12.850613Z","shell.execute_reply":"2025-01-07T10:31:12.861468Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"torch.manual_seed(0)\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T10:31:12.864336Z","iopub.execute_input":"2025-01-07T10:31:12.864813Z","iopub.status.idle":"2025-01-07T10:31:12.883174Z","shell.execute_reply.started":"2025-01-07T10:31:12.864753Z","shell.execute_reply":"2025-01-07T10:31:12.881999Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Implement a dataset class. Focus on the getitem method to return:\n# – X: A tensor of node coordinates with size 20 × 2.\n# – y: A tour starting from 0 and ending with 0.\n\nclass GraphDataset(Dataset):\n    def __init__(self, data):\n        \"\"\"\n        A list of tuples where each tuple contains:\n        - A networkx.Graph object\n        - A tour (list of node indices)\n        \"\"\"\n        self.data = data\n\n    def __len__(self):\n        \"\"\"\n        Number of instances in the dataset\n        \"\"\"\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        \"\"\"\n        Returns:\n        - X: A tensor of node coordinates with size 20 × 2.\n        - y: A tensor representing the tour, starting and ending at 0.\n        \"\"\"\n        # Extract the graph and tour\n        graph, tour = self.data[idx]\n\n        # Get node positions as a 2D array\n        pos = nx.get_node_attributes(graph, 'pos')  # Dictionary {node: (x, y)}\n        if not pos:\n            raise ValueError(f\"Graph at index {idx} is missing node positions ('pos').\")\n\n        # Ensure nodes are sorted by their index (important for consistent tensor order)\n        sorted_positions = [pos[node] for node in sorted(graph.nodes())]\n        \n        # Convert positions to a tensor of shape (20, 2)\n        X = torch.tensor(sorted_positions, dtype=torch.float32)\n\n        # Convert the tour to a tensor\n        y = torch.tensor(tour, dtype=torch.long)\n\n        return X, y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T10:31:12.884760Z","iopub.execute_input":"2025-01-07T10:31:12.885128Z","iopub.status.idle":"2025-01-07T10:31:12.893677Z","shell.execute_reply.started":"2025-01-07T10:31:12.885093Z","shell.execute_reply":"2025-01-07T10:31:12.892591Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Dummy\n# Create Dataset objects for training, validation, and testing, along with their respective Dataloader\n# dataset = GraphDataset(dummy)\n# train_dataset, val_dataset, test_dataset = random_split(dataset, [0.8, 0.1, 0.1])\n\n# batch_size = 32\n\n# trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n# valloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n# testloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T10:31:12.897559Z","iopub.execute_input":"2025-01-07T10:31:12.898032Z","iopub.status.idle":"2025-01-07T10:31:12.914450Z","shell.execute_reply.started":"2025-01-07T10:31:12.897995Z","shell.execute_reply":"2025-01-07T10:31:12.913136Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"#with open('/kaggle/input/tspinstances/train_20_DLL_ass4.pkl', 'rb') as file:\n#    train = pickle.load(file)\n\nwith open('/kaggle/input/tspinstances/test_20_DLL_ass4.pkl', 'rb') as file:\n    test = pickle.load(file)\n\nwith open('/kaggle/input/tspinstances/valid_20_DLL_ass4.pkl', 'rb') as file:\n    valid = pickle.load(file)\n\nbatch_size = 32\n\ntrain_dataset = GraphDataset(train)\nval_dataset = GraphDataset(valid)\ntest_dataset = GraphDataset(test)\n\ntrainloader = DataLoader(train_dataset, batch_size=batch_size)\nvalloader = DataLoader(val_dataset, batch_size=batch_size)\ntestloader = DataLoader(test_dataset, batch_size=batch_size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T10:31:12.916583Z","iopub.execute_input":"2025-01-07T10:31:12.917064Z","iopub.status.idle":"2025-01-07T10:31:13.472605Z","shell.execute_reply.started":"2025-01-07T10:31:12.917026Z","shell.execute_reply":"2025-01-07T10:31:13.471465Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"class PositionalEncoding(nn.Module):\n    def __init__(self,emb_size: int, dropout: float, maxlen: int = 5000):\n        super(PositionalEncoding, self).__init__()\n\n        pos_embedding = torch.zeros((maxlen, emb_size))\n        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)   \n        \n        pos_embedding[:, 0::2] = torch.sin(pos * den)\n        pos_embedding[:, 1::2] = torch.cos(pos * den)\n        pos_embedding = pos_embedding.unsqueeze(-2)\n\n        self.dropout = nn.Dropout(dropout)\n        self.register_buffer('pos_embedding', pos_embedding)\n\n    def forward(self, token_embedding: Tensor):\n        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n\n# n = 20\n# n_enc = 4\n# n_dec = 4\n# de = 32\n# dd = 32\n# N_HEAD = 8\n# DROPOUT = 0.1\n\nclass TSPTransformer(nn.Module):\n    def __init__(self, n, num_encoder, num_decoder, de, dd, n_head, dropout, dim_feedforward=1024):\n        super().__init__()\n        # Encoder\n        self.linear1 = nn.Linear(2, de)\n        encoder_layer = nn.TransformerEncoderLayer(d_model=de, nhead=n_head, dim_feedforward=dim_feedforward, batch_first=True) # d_model (int) – the number of expected features in the input (required).\n        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_encoder) # stack of n encoder layers\n        self.linear2 = nn.Linear(de, dd)\n        \n        # Decoder\n        self.embedding = nn.Embedding(n, dd)\n        self.posEncoding = PositionalEncoding(dd, dropout)\n        decoder_layer = nn.TransformerDecoderLayer(d_model=dd, nhead=n_head, dim_feedforward=dim_feedforward, batch_first=True)\n        self.decoder = nn.TransformerDecoder(decoder_layer, num_layers=num_decoder)\n        self.ffnn = nn.Linear(dd, n)\n\n    \n    def forward(self,\n                src: Tensor,\n                trg: Tensor,\n                src_mask: Tensor,\n                tgt_mask: Tensor,\n                src_padding_mask: Tensor,\n                tgt_padding_mask: Tensor):\n\n        \n        # Encoding\n        src = self.linear1(src)\n        # Change: No mask for the encoder or an additive mask of zeros\n        src = self.encoder(src, mask=src_mask, src_key_padding_mask=src_padding_mask)\n        src = self.linear2(src)\n\n        # Decoding\n        trg = self.embedding(trg)\n        trg = self.posEncoding(trg)\n        output = self.decoder(trg, src, tgt_mask=tgt_mask, memory_mask=None,\n                            tgt_key_padding_mask=tgt_padding_mask,\n                            memory_key_padding_mask=src_padding_mask)\n        output = self.ffnn(output)\n        return output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T10:31:13.474132Z","iopub.execute_input":"2025-01-07T10:31:13.474564Z","iopub.status.idle":"2025-01-07T10:31:13.491170Z","shell.execute_reply.started":"2025-01-07T10:31:13.474513Z","shell.execute_reply":"2025-01-07T10:31:13.489810Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def generate_square_subsequent_mask(sequence_length: int) -> Tensor:\n    mask = (torch.triu(torch.ones((sequence_length, sequence_length), device=DEVICE)) == 1).transpose(0, 1)\n    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n    return mask\n\n\ndef create_mask(src, tgt, DEVICE):\n    src_seq_len = src.shape[1]\n    tgt_seq_len = tgt.shape[1]\n\n    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n    src_mask = torch.zeros((src_seq_len, src_seq_len), device=DEVICE).type(torch.bool)\n\n    src_padding_mask = torch.zeros((src.shape[0], src_seq_len), device=DEVICE).bool() # Corrected\n    tgt_padding_mask = torch.zeros((tgt.shape[0], tgt_seq_len), device=DEVICE).bool() # Corrected\n\n    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T10:31:13.492963Z","iopub.execute_input":"2025-01-07T10:31:13.493422Z","iopub.status.idle":"2025-01-07T10:31:13.517410Z","shell.execute_reply.started":"2025-01-07T10:31:13.493373Z","shell.execute_reply":"2025-01-07T10:31:13.516056Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"$n$ = num di nodes -> Each TSP instance has exactly 20 nodes, and the input consists of their 2D coordinates.\n\n$de$ = size of the internal rapresentation of the input coordinates\n       2 feature per node -> small values like 16, 32, 64\n\n$dd$ = size of intermediate representation\n     y is a sequence of discrete node indeces, typical equal to de but also higher\n\n$Ne$ = num encoeer layers -> 2,4,6\n\n$Nd$ = num decoder layers -> equal to Ne but also higher","metadata":{}},{"cell_type":"code","source":"# d_e=512, d_d=512, num_encoder_layers=6\n# num_decoder_layers=6, dropout=0.2\nn = 20\nn_enc = 6\nn_dec = 6\nde = 128\ndd = 128\nN_HEAD = 8\nDROPOUT = 0.3\ndim_feedforward=1024 #(se non specificato 1024 in mio modello)\n\nTSPmodel = TSPTransformer(n, n_enc, n_dec, de, dd, N_HEAD, DROPOUT, dim_feedforward).to(DEVICE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T10:31:13.519007Z","iopub.execute_input":"2025-01-07T10:31:13.519400Z","iopub.status.idle":"2025-01-07T10:31:13.724735Z","shell.execute_reply.started":"2025-01-07T10:31:13.519365Z","shell.execute_reply":"2025-01-07T10:31:13.723564Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"markdown","source":"### Training WITHOUT gradient accumulation","metadata":{}},{"cell_type":"code","source":"# Function for training a single epoch\ndef train_epoch(model, optimizer, trainloader, loss_fn, DEVICE):\n    model.train()\n    losses = 0\n\n    for src, tgt in trainloader:\n        src = src.to(DEVICE)  # Node coordinates (input to the encoder)\n        tgt = tgt.to(DEVICE)  # Tour indices (target sequence for the decoder)\n\n        tgt_input = tgt[:, :-1]  # Input to the decoder (shifted by one token)\n        tgt_out = tgt[:, 1:]  # Target for loss computation (shifted by one token)\n\n        optimizer.zero_grad()\n\n        # Generate masks for attention\n        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input, DEVICE)\n        # Forward pass\n        output = model(src, tgt_input, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask)\n\n        loss = loss_fn(output.reshape(-1, output.shape[-1]), tgt_out.reshape(-1))\n        loss.backward()\n\n        # gradient clipping to prevent exploding gradients\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n\n        # Update weights\n        optimizer.step()\n        losses += loss.item()\n\n    return losses / len(trainloader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T10:31:13.726267Z","iopub.execute_input":"2025-01-07T10:31:13.726699Z","iopub.status.idle":"2025-01-07T10:31:13.737193Z","shell.execute_reply.started":"2025-01-07T10:31:13.726651Z","shell.execute_reply":"2025-01-07T10:31:13.735999Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# Function for evaluation\ndef evaluate(model, valloader, loss_fn, DEVICE, num_heads):\n    model.eval()\n    losses = 0\n\n    with torch.no_grad():\n        for src, tgt in valloader:\n            src = src.to(DEVICE)  # Node coordinates (input to the encoder)\n            tgt = tgt.to(DEVICE)  # Tour indices (target sequence for the decoder)\n          \n            tgt_input = tgt[:, :-1]  # Input to the decoder (shifted by one token)\n            tgt_out = tgt[:, 1:]  # Target for loss computation (shifted by one token)\n\n            # Generate masks for attention\n            src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input, DEVICE)\n\n            # Forward pass\n            output = model(src, tgt_input, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask)\n\n            loss = loss_fn(output.reshape(-1, output.shape[-1]), tgt_out.reshape(-1))\n            losses += loss.item()\n\n    avg_loss = losses / len(valloader)\n    return avg_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T10:31:13.738553Z","iopub.execute_input":"2025-01-07T10:31:13.738929Z","iopub.status.idle":"2025-01-07T10:31:13.757264Z","shell.execute_reply.started":"2025-01-07T10:31:13.738858Z","shell.execute_reply":"2025-01-07T10:31:13.756068Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"warnings.filterwarnings(\"ignore\")\n\n# hyperparameters\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.AdamW(TSPmodel.parameters(), lr=0.0002, betas=(0.9, 0.98), eps=1e-9, weight_decay=0.01)\n\n# Training configuration\nNUM_EPOCHS = 15\ntrain_losses = []\nval_losses = []\ncounter = 0\n\nbest_epoch = 0\nprint_every = 3\nbest_val_loss = float('inf')\n\n# start_tot_time = timer()\n# # Training loop\n# for epoch in range(1, NUM_EPOCHS + 1):\n#     start_time = timer()\n    \n#     # Train for one epoch\n#     train_loss = train_epoch(TSPmodel, optimizer, trainloader, loss_fn, DEVICE)    \n    \n#     # Evaluate on validation data\n#     val_loss = evaluate(TSPmodel, valloader, loss_fn, DEVICE, N_HEAD)\n#     end_time = timer()\n\n#     if best_val_loss < val_loss:\n#         counter += 1\n#     else:\n#         counter = 0\n#         best_val_loss = val_loss\n#         # save the best model\n#         torch.save({\n#                 'epoch': epoch,\n#                 'model_state_dict': TSPmodel.state_dict(),\n#                 'optimizer_state_dict': optimizer.state_dict(),\n#                 'train_loss': train_loss,\n#                 'val_loss': val_loss,\n#             }, 'model.pt')\n#         best_epoch = epoch\n\n#     # Log losses\n#     train_losses.append(train_loss)\n#     val_losses.append(val_loss)\n\n#     end_tot_time = timer() - start_tot_time\n\n#     if epoch % print_every == 0:\n#         print(f\"Epoch: {epoch}\")\n#         print(f\"   Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}\")\n#         print(f\"   Epoch time = {(end_time - start_time):.3f}s\")\n    \n#     if counter == 5:\n#         print(f'Overfitting at epoch {epoch}')\n#         break\n#     elif end_tot_time >= 600:\n#         print(f'Reached ten minutes of training without overfitting at epoch {epoch}')\n#         break\n\n# print(f'Training time: {end_tot_time/60} minuti')\n# print(f\"The best model is obtained at epoch {best_epoch} with a training loss of {train_losses[best_epoch-1]:.3f} and evaluation loss of {best_val_loss:.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T10:31:13.758528Z","iopub.execute_input":"2025-01-07T10:31:13.758938Z","iopub.status.idle":"2025-01-07T10:31:16.474694Z","shell.execute_reply.started":"2025-01-07T10:31:13.758863Z","shell.execute_reply":"2025-01-07T10:31:16.473488Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# # Plot training and validation losses\n# plt.plot(train_losses, label='Training Loss')\n# plt.plot(val_losses, label='Validation Loss')\n# plt.xlabel('Epoch')\n# plt.ylabel('Loss')\n# plt.title('Training and Validation Loss')\n# plt.legend()\n# plt.show()\n\n# print(train_losses, val_losses)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T10:31:16.476114Z","iopub.execute_input":"2025-01-07T10:31:16.476645Z","iopub.status.idle":"2025-01-07T10:31:16.481937Z","shell.execute_reply.started":"2025-01-07T10:31:16.476607Z","shell.execute_reply":"2025-01-07T10:31:16.480376Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"### Training WITH gradient accumulation","metadata":{}},{"cell_type":"code","source":"def train_epoch_acc(model, optimizer, trainloader, loss_fn, DEVICE, accum_iter=4):\n    model.train()\n    losses = 0\n    optimizer.zero_grad()\n\n    for batch_idx, (src, tgt) in enumerate(trainloader):\n        src = src.to(DEVICE)  # Node coordinates (input to the encoder)\n        tgt = tgt.to(DEVICE)  # Tour indices (target sequence for the decoder)\n\n        tgt_input = tgt[:, :-1]  # Input to the decoder (shifted by one token)\n        tgt_out = tgt[:, 1:]  # Target for loss computation (shifted by one token)\n\n        # Generate masks for attention\n        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input, DEVICE)\n\n        # Forward pass\n        output = model(src, tgt_input, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask)\n        \n        # Compute the loss divided by accum_iter for gradient accumulation\n        loss = loss_fn(output.reshape(-1, output.shape[-1]), tgt_out.reshape(-1)) / accum_iter\n        loss.backward()\n\n        if (batch_idx + 1) % accum_iter == 0 or (batch_idx + 1 == len(trainloader)):\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Optional: Gradient clipping\n            optimizer.step()\n            optimizer.zero_grad()\n\n        # Accumulate the actual (unscaled) loss for logging\n        losses += loss.item() * accum_iter\n\n    return losses / len(trainloader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T10:31:16.483402Z","iopub.execute_input":"2025-01-07T10:31:16.483763Z","iopub.status.idle":"2025-01-07T10:31:16.505226Z","shell.execute_reply.started":"2025-01-07T10:31:16.483725Z","shell.execute_reply":"2025-01-07T10:31:16.503965Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"modelACC = TSPTransformer(n, n_enc, n_dec, de, dd, N_HEAD, DROPOUT, dim_feedforward).to(DEVICE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T10:31:16.506763Z","iopub.execute_input":"2025-01-07T10:31:16.507209Z","iopub.status.idle":"2025-01-07T10:31:16.565288Z","shell.execute_reply.started":"2025-01-07T10:31:16.507174Z","shell.execute_reply":"2025-01-07T10:31:16.563905Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"warnings.filterwarnings(\"ignore\")\n\n# hyperparameters\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.AdamW(modelACC.parameters(), lr=0.0002, betas=(0.9, 0.98), eps=1e-9, weight_decay=0.01)\n\n# Training configuration\nNUM_EPOCHS = 15\ntrain_losses = []\nval_losses = []\ncounter = 0\n\nbest_epoch = 0\nprint_every = 3\nbest_val_loss = float('inf')\n\n# start_tot_time = timer()\n# # Training loop\n# for epoch in range(1, NUM_EPOCHS + 1):\n#     start_time = timer()\n    \n#     # Train for one epoch\n#     train_loss = train_epoch_acc(modelACC, optimizer, trainloader, loss_fn, DEVICE)    \n    \n#     # Evaluate on validation data\n#     val_loss = evaluate(modelACC, valloader, loss_fn, DEVICE, N_HEAD)\n#     end_time = timer()\n\n#     if best_val_loss < val_loss:\n#         counter += 1\n#     else:\n#         counter = 0\n#         best_val_loss = val_loss\n#         # save the best model\n#         torch.save({\n#                 'epoch': epoch,\n#                 'model_state_dict': modelACC.state_dict(),\n#                 'optimizer_state_dict': optimizer.state_dict(),\n#                 'train_loss': train_loss,\n#                 'val_loss': val_loss,\n#             }, 'model_acc.pt')\n#         best_epoch = epoch\n\n#     # Log losses\n#     train_losses.append(train_loss)\n#     val_losses.append(val_loss)\n\n#     end_tot_time = timer() - start_tot_time\n\n#     if epoch % print_every == 0:\n#         print(f\"Epoch: {epoch}\")\n#         print(f\"   Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}\")\n#         print(f\"   Epoch time = {(end_time - start_time):.3f}s\")\n    \n#     if counter == 5:\n#         print(f'Overfitting at epoch {epoch}')\n#         break\n#     elif end_tot_time >= 600:\n#         print(f'Reached ten minutes of training without overfitting at epoch {epoch}')\n#         break\n\n# print(f'Training time: {end_tot_time/60} minuti')\n# print(f\"The best model is obtained at epoch {best_epoch} with a training loss of {train_losses[best_epoch-1]} and evaluation loss of {best_val_loss}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T10:31:16.566800Z","iopub.execute_input":"2025-01-07T10:31:16.567195Z","iopub.status.idle":"2025-01-07T10:31:16.576174Z","shell.execute_reply.started":"2025-01-07T10:31:16.567161Z","shell.execute_reply":"2025-01-07T10:31:16.574823Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# # Plot training and validation losses\n# plt.plot(train_losses, label='Training Loss')\n# plt.plot(val_losses, label='Validation Loss')\n# plt.xlabel('Epoch')\n# plt.ylabel('Loss')\n# plt.title('Training and Validation Loss with gradient accumulation')\n# plt.legend()\n# plt.show()\n\n# print(train_losses, val_losses)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T10:31:16.577594Z","iopub.execute_input":"2025-01-07T10:31:16.578018Z","iopub.status.idle":"2025-01-07T10:31:16.596910Z","shell.execute_reply.started":"2025-01-07T10:31:16.577976Z","shell.execute_reply":"2025-01-07T10:31:16.595836Z"}},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":"## Testing","metadata":{}},{"cell_type":"markdown","source":"Test your model on the test set and compare it with two baselines:\n\n- random tour: Samples a random tour.\n- greedy algorithm: Starts from a node and selects the closest unvisited\nnode iteratively.","metadata":{}},{"cell_type":"code","source":"model = torch.load('/kaggle/input/tsp_models/pytorch/default/1/model.pt')\n\nmodel_GA = torch.load('/kaggle/input/tsp_models/pytorch/default/1/model_acc.pt')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T10:31:45.438508Z","iopub.execute_input":"2025-01-07T10:31:45.439001Z","iopub.status.idle":"2025-01-07T10:31:47.016213Z","shell.execute_reply.started":"2025-01-07T10:31:45.438962Z","shell.execute_reply":"2025-01-07T10:31:47.015064Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"graph, tour = test[0]\ngraph, tour","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T10:31:57.456781Z","iopub.execute_input":"2025-01-07T10:31:57.457195Z","iopub.status.idle":"2025-01-07T10:31:57.465324Z","shell.execute_reply.started":"2025-01-07T10:31:57.457162Z","shell.execute_reply":"2025-01-07T10:31:57.463939Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"(<networkx.classes.graph.Graph at 0x786076d28820>,\n [0, 4, 5, 9, 18, 15, 11, 10, 2, 8, 12, 3, 7, 6, 16, 1, 13, 19, 14, 17, 0])"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"print(gap(graph, model, device=DEVICE))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-07T10:38:34.912023Z","iopub.execute_input":"2025-01-07T10:38:34.912539Z","iopub.status.idle":"2025-01-07T10:38:34.972169Z","shell.execute_reply.started":"2025-01-07T10:38:34.912492Z","shell.execute_reply":"2025-01-07T10:38:34.970468Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mgap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m)\n","Cell \u001b[0;32mIn[2], line 85\u001b[0m, in \u001b[0;36mgap\u001b[0;34m(G, model, model_GA, random_seed, device)\u001b[0m\n\u001b[1;32m     83\u001b[0m gaps \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgreedy\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransformer_tsp\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransformer_tsp_acc_grad\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m}\n\u001b[1;32m     84\u001b[0m gaps[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgreedy\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\u001b[38;5;241m*\u001b[39m (greedy_algorithm(G) \u001b[38;5;241m-\u001b[39m  TSP) \u001b[38;5;241m/\u001b[39m TSP\n\u001b[0;32m---> 85\u001b[0m gaps[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m*\u001b[39m (\u001b[43mrandom_tour\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mTSP\u001b[49m) \u001b[38;5;241m/\u001b[39m TSP\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     87\u001b[0m     gaps[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransformer_tsp\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m*\u001b[39m (transformer_tsp(G, model, DEVICE\u001b[38;5;241m=\u001b[39mdevice) \u001b[38;5;241m-\u001b[39m TSP) \u001b[38;5;241m/\u001b[39m TSP\n","\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'NoneType' and 'float'"],"ename":"TypeError","evalue":"unsupported operand type(s) for -: 'NoneType' and 'float'","output_type":"error"}],"execution_count":29},{"cell_type":"code","source":"print(gap(graph, model_GA, device=DEVICE))","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}